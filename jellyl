#!/usr/bin/env bash

url_list="$( cat /home/jjenkx/.local/input_files/jelly_dl.txt )" 

SAVEIFS=$IFS          # Save current IFS (Internal Field Separator)
IFS=$'\n'             # Change IFS to newline char
url_list=($url_list)  # split the `url_list` string into an array by the same name
IFS=$SAVEIFS          # Restore original IFS

# Download Jellyfin URLs one at a time
for (( i=0; i<${#url_list[@]}; i++ ))
do
  filename="$(  curl -i "${url_list[$i]}" 2>/dev/null | head | sed -n 's/.*filename="\([^"]*\)".*/\1/p'  )"
  format_filename="$(  cat <<< "$filename" | sed 's/[][(). ]\+/\./g' | sed 's/\.-/-/g' | sed 's/\(Remux\|WEBDL\)-/\1./g'  )"
  aria2c \
    --allow-piece-length-change=true \
    --check-certificate=false \
    --console-log-level=notice \
    --content-disposition-default-utf8=true \
    --continue=true \
    --disk-cache=8192 \
    --download-result=full \
    --file-allocation=none \
    --max-concurrent-downloads=1 \
    --max-connection-per-server=1 \
    --max-resume-failure-tries=64 \
    --max-file-not-found=64 \
    --max-tries=64 \
    --min-split-size=5M \
    --out="$format_filename" \
    --piece-length=5M \
    --realtime-chunk-checksum=true \
    --retry-on-400=true \
    --retry-on-403=true \
    --retry-on-406=true \
    --retry-on-unknown=true \
    --retry-wait=120 \
    --split=1 \
    --summary-interval=180 \
    --stream-piece-selector=geom \
    --timeout=10 \
    --user-agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36' \
  "${url_list[$i]}"
done
